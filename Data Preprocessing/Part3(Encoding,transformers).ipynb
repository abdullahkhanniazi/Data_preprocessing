{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import plotly as pl \n",
    "import seaborn as sns \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables\n",
    "\n",
    "#### There are two types of categorical data\n",
    "##### 1: Nominal \n",
    "##### 2: Ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "##### In label encoding, each unique category value is assigned an integer based on alphabetical order or occurrence. It works well when the categorical data has an intrinsic order\n",
    "\n",
    "##### Label encoding is helpful when you are working on output column when for example it give answere like either customer buy the product or not and result column contain values like 'yes' and 'No' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "data = ['Class A', 'Class B', 'Class C', 'Class A']\n",
    "encoder = LabelEncoder()\n",
    "encoded_data = encoder.fit_transform(data)\n",
    "\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding\n",
    "##### Ordinal encoding is useful when the categorical values have a clear, natural order. It maps each unique value to an integer but maintains the ordinal relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [1. 1.]\n",
      " [2. 2.]\n",
      " [1. 0.]\n",
      " [2. 1.]\n",
      " [0. 2.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"Size\": [\"small\", \"medium\", \"Large\", \"medium\", \"Large\", \"small\"],\n",
    "    \"temperature\": ['low', 'medium', 'high', 'low', 'medium', 'high']\n",
    "})\n",
    "\n",
    "O_encoder = OrdinalEncoder(categories=[[\"small\",\"medium\",\"Large\"], ['low','medium', \"high\"]])\n",
    "O_encoder\n",
    "O_encoder.fit(data)\n",
    "encoded_data = O_encoder.transform(data)\n",
    "\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.29</td>\n",
       "      <td>4.71</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.77</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.88</td>\n",
       "      <td>3.12</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.04</td>\n",
       "      <td>1.96</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.78</td>\n",
       "      <td>3.23</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
       "5       25.29  4.71    Male     No  Sun  Dinner     4\n",
       "6        8.77  2.00    Male     No  Sun  Dinner     2\n",
       "7       26.88  3.12    Male     No  Sun  Dinner     4\n",
       "8       15.04  1.96    Male     No  Sun  Dinner     2\n",
       "9       14.78  3.23    Male     No  Sun  Dinner     2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"tips\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "dt_columns = df[[\"sex\",\"smoker\",\"day\",\"time\"]]\n",
    "# dt_columns\n",
    "encoded_data = encoder.fit_transform(df[[\"day\"]])\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdullah khan\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoded_data = encoder.fit_transform(df[[\"time\"]])\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need to train test siplit before encoding also for Ordinal Encoder you have to pass list like\n",
    "##### oe = OrdinalEncoder(categrories=[['low','Average','good','Excellent']]) this will help full because you will\n",
    "##### understande the data when it is in action that 0 for low and 1 for avergae and so on otherwise algoritham dicide by himself randomly\n",
    "##### Also you can pass mulitple lists like\n",
    "##### oe = OrdinalEncoder(categrories=[['low','Average','good','Excellent'],['school','college','university']]) this will help full because you will"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>class_First</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare    who  adult_male deck  \\\n",
       "0         0       3  22.0      1      0   7.2500    man        True  NaN   \n",
       "1         1       1  38.0      1      0  71.2833  woman       False    C   \n",
       "2         1       3  26.0      0      0   7.9250  woman       False  NaN   \n",
       "3         1       1  35.0      1      0  53.1000  woman       False    C   \n",
       "4         0       3  35.0      0      0   8.0500    man        True  NaN   \n",
       "\n",
       "   embark_town alive  alone  sex_female  sex_male  embarked_C  embarked_Q  \\\n",
       "0  Southampton    no  False       False      True       False       False   \n",
       "1    Cherbourg   yes  False        True     False        True       False   \n",
       "2  Southampton   yes   True        True     False       False       False   \n",
       "3  Southampton   yes  False        True     False       False       False   \n",
       "4  Southampton    no   True       False      True       False       False   \n",
       "\n",
       "   embarked_S  class_First  class_Second  class_Third  \n",
       "0        True        False         False         True  \n",
       "1       False         True         False        False  \n",
       "2        True        False         False         True  \n",
       "3        True         True         False        False  \n",
       "4        True        False         False         True  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding using pandas get_dummies\n",
    "dt = sns.load_dataset('titanic')\n",
    "dt.sample(5)\n",
    "dt.head(5)\n",
    "\n",
    "# Applying One-Hot Encoding to 'sex', 'embarked', and 'class' columns\n",
    "titanic_encoded = pd.get_dummies(dt, columns=['sex', 'embarked', 'class'])\n",
    "\n",
    "titanic_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 2673 stored elements and shape (891, 9)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 6)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (2, 8)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (3, 6)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (4, 8)\t1.0\n",
      "  (5, 1)\t1.0\n",
      "  (5, 3)\t1.0\n",
      "  (5, 8)\t1.0\n",
      "  (6, 1)\t1.0\n",
      "  (6, 4)\t1.0\n",
      "  (6, 6)\t1.0\n",
      "  (7, 1)\t1.0\n",
      "  (7, 4)\t1.0\n",
      "  (7, 8)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  :\t:\n",
      "  (882, 8)\t1.0\n",
      "  (883, 1)\t1.0\n",
      "  (883, 4)\t1.0\n",
      "  (883, 7)\t1.0\n",
      "  (884, 1)\t1.0\n",
      "  (884, 4)\t1.0\n",
      "  (884, 8)\t1.0\n",
      "  (885, 0)\t1.0\n",
      "  (885, 3)\t1.0\n",
      "  (885, 8)\t1.0\n",
      "  (886, 1)\t1.0\n",
      "  (886, 4)\t1.0\n",
      "  (886, 7)\t1.0\n",
      "  (887, 0)\t1.0\n",
      "  (887, 4)\t1.0\n",
      "  (887, 6)\t1.0\n",
      "  (888, 0)\t1.0\n",
      "  (888, 4)\t1.0\n",
      "  (888, 8)\t1.0\n",
      "  (889, 1)\t1.0\n",
      "  (889, 2)\t1.0\n",
      "  (889, 6)\t1.0\n",
      "  (890, 1)\t1.0\n",
      "  (890, 3)\t1.0\n",
      "  (890, 8)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "df.sample(5)\n",
    "cat_col = df[['sex', 'embarked', 'class']]\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(cat_col)\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 2673 stored elements and shape (891, 9)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 6)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (2, 8)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (3, 6)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (4, 8)\t1.0\n",
      "  (5, 1)\t1.0\n",
      "  (5, 3)\t1.0\n",
      "  (5, 8)\t1.0\n",
      "  (6, 1)\t1.0\n",
      "  (6, 4)\t1.0\n",
      "  (6, 6)\t1.0\n",
      "  (7, 1)\t1.0\n",
      "  (7, 4)\t1.0\n",
      "  (7, 8)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  :\t:\n",
      "  (882, 8)\t1.0\n",
      "  (883, 1)\t1.0\n",
      "  (883, 4)\t1.0\n",
      "  (883, 7)\t1.0\n",
      "  (884, 1)\t1.0\n",
      "  (884, 4)\t1.0\n",
      "  (884, 8)\t1.0\n",
      "  (885, 0)\t1.0\n",
      "  (885, 3)\t1.0\n",
      "  (885, 8)\t1.0\n",
      "  (886, 1)\t1.0\n",
      "  (886, 4)\t1.0\n",
      "  (886, 7)\t1.0\n",
      "  (887, 0)\t1.0\n",
      "  (887, 4)\t1.0\n",
      "  (887, 6)\t1.0\n",
      "  (888, 0)\t1.0\n",
      "  (888, 4)\t1.0\n",
      "  (888, 8)\t1.0\n",
      "  (889, 1)\t1.0\n",
      "  (889, 2)\t1.0\n",
      "  (889, 6)\t1.0\n",
      "  (890, 1)\t1.0\n",
      "  (890, 3)\t1.0\n",
      "  (890, 8)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Let's first train test the above code \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "df.sample(5)\n",
    "\n",
    "# cat_col = df[['sex', 'embarked', 'class']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(cat_col.iloc[:,[0,1]],cat_col.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "X_train\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(cat_col)\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this encoding we carefully learn and work on multicoliniarity: where we remove one column because if we do not remove one column and we add all column after OHE the output will be 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>fever</th>\n",
       "      <th>cough</th>\n",
       "      <th>city</th>\n",
       "      <th>has_covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>42.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>98.403217</td>\n",
       "      <td>Low</td>\n",
       "      <td>New York</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>100.257814</td>\n",
       "      <td>Low</td>\n",
       "      <td>New York</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>99.000554</td>\n",
       "      <td>High</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>104.376560</td>\n",
       "      <td>High</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>58.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>102.053740</td>\n",
       "      <td>High</td>\n",
       "      <td>New York</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender       fever cough      city has_covid\n",
       "105  42.0  Female   98.403217   Low  New York        No\n",
       "127  33.0  Female  100.257814   Low  New York       Yes\n",
       "25   53.0  Female   99.000554  High   Phoenix       Yes\n",
       "73   24.0    Male  104.376560  High   Chicago        No\n",
       "345  58.0    Male  102.053740  High  New York       Yes"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.read_csv(\"D:\\\\Machine learning\\\\DataSets\\\\covid_data_with_missing_values.csv\")\n",
    "dt.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "Houston        108\n",
       "Chicago        105\n",
       "New York        98\n",
       "Phoenix         96\n",
       "Los Angeles     93\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dt.isnull().sum()\n",
    "# dt.info()\n",
    "# dt[\"cough\"].value_counts()\n",
    "dt[\"city\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   age        480 non-null    float64\n",
      " 1   gender     500 non-null    object \n",
      " 2   fever      480 non-null    float64\n",
      " 3   cough      500 non-null    object \n",
      " 4   city       500 non-null    object \n",
      " 5   has_covid  500 non-null    object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 23.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# let's fill missing values \n",
    "# Condsider this as dummy it will not effect the orignal outcome if we replace it with mean values\n",
    "dt[dt[\"age\"].isnull()]\n",
    "\n",
    "# dt[\"age\"].fillna(dt[\"age\"].mean(),inplace=True)\n",
    "# dt[dt[\"age\"].isnull()]\n",
    "\n",
    "# dt[\"fever\"].fillna(dt[\"fever\"].mean(),inplace=True)\n",
    "# dt[dt[\"fever\"].isnull()]\n",
    "\n",
    "\n",
    "dt[\"age\"] = dt[\"age\"].astype(\"int\")\n",
    "dt[\"fever\"] = dt[\"fever\"].astype(\"int\")\n",
    "\n",
    "# dt[\"age\"].dtype\n",
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249    Yes\n",
       "433    Yes\n",
       "19     Yes\n",
       "322     No\n",
       "332     No\n",
       "      ... \n",
       "106     No\n",
       "270     No\n",
       "348     No\n",
       "435    Yes\n",
       "102     No\n",
       "Name: has_covid, Length: 400, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train test siplit\n",
    "X_train, X_test, y_train, y_test = train_test_split(dt.drop(columns=[\"has_covid\"]), dt[\"has_covid\"], test_size=0.2, random_state=42)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without column transformer we have to transform each and every column separatly then concatinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[\n",
    "    ('tranf1', SimpleImputer(),[\"age\",\"fever\"]),\n",
    "    ('tranf2',OrdinalEncoder(categories=[[\"Low\",\"High\"]]),[\"cough\"]),\n",
    "    ('tranf3',OneHotEncoder(sparse_output=False,drop=\"first\"),[\"gender\",\"city\"])],\n",
    "                                remainder=\"passthrough\")   # transformer get the list of columns need to tranform and reminder get the column other then that you can either 'drop' them or contain remain the same we will use term 'passthrough'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 27.        , 102.46455633,   1.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 24.        , 104.37655986,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 37.        , 101.82645015,   1.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 63.        , 104.12314221,   0.        ,   1.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 43.40816327,  99.92800267,   0.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 26.        , 104.8947006 ,   0.        ,   1.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 65.        , 101.53016967,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 53.        ,  97.27817525,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 69.        , 100.06634088,   0.        ,   1.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 37.        ,  99.84364   ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 46.        ,  99.02809351,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 42.        , 104.46063518,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 28.        ,  99.43608086,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 32.        ,  97.88463312,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 68.        , 103.32482831,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 19.        ,  97.57980702,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 27.        ,  97.84385569,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 50.        , 102.59956172,   0.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 39.        , 102.58887422,   1.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 48.        ,  98.93924353,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 45.        ,  99.18748935,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 28.        , 102.01608376,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 59.        ,  97.76886142,   1.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 49.        , 101.39587834,   0.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 46.        ,  97.24858549,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 59.        , 103.54263053,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 58.        , 100.87029237,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 23.        , 103.95772563,   1.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 54.        , 103.55758243,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 67.        , 101.4464657 ,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 59.        , 100.87029237,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 35.        ,  98.74810589,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 37.        , 102.21112521,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 33.        , 103.09213755,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 32.        , 104.02494649,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 47.        ,  98.32122276,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 58.        , 102.79810122,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 69.        , 101.08981795,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 37.        , 100.47263325,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 56.        , 103.38687447,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 24.        , 101.36840174,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 41.        , 101.97202803,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 18.        ,  99.32011165,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 29.        , 104.43096353,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 35.        , 103.16369941,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 40.        , 100.23288974,   1.        ,   1.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 53.        , 100.18193241,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 49.        , 102.45351511,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 24.        ,  99.1615818 ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 18.        , 100.46999104,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 40.        ,  98.06559823,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 56.        , 100.74131805,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 36.        ,  99.63058107,   1.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 42.        ,  99.02883473,   0.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 28.        ,  97.54847691,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 65.        ,  97.41335595,   0.        ,   1.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 37.        ,  97.75436128,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 52.        , 101.25991482,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 20.        , 100.41764039,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 21.        , 100.87029237,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 52.        ,  98.96436311,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 46.        , 101.96588712,   1.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 31.        , 100.60155855,   0.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 19.        , 102.97535608,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 60.        ,  99.4511133 ,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 44.        ,  97.81589115,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 19.        , 100.08035061,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 60.        , 104.53594299,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 68.        ,  97.53255676,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 22.        , 101.32520254,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 57.        ,  98.36420877,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 25.        ,  98.02194285,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 43.40816327, 101.14307627,   0.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 45.        , 102.97993616,   1.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 64.        ,  98.02437686,   1.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 47.        ,  99.14198981,   0.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 45.        , 100.88751752,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 21.        , 104.25930291,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 18.        , 103.27931471,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 57.        ,  98.71795375,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 39.        , 102.24452931,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 45.        ,  98.82585465,   1.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 27.        , 100.09583279,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 22.        , 101.2621266 ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 65.        , 100.51056855,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 31.        , 104.64743806,   1.        ,   1.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 49.        , 100.26172388,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 53.        , 103.55227232,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 47.        ,  98.61796484,   1.        ,   1.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 66.        , 104.25688786,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 67.        , 100.19213512,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 37.        , 103.04421045,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 65.        ,  99.52677182,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 51.        , 102.43526398,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ,   0.        ,   0.        ],\n",
       "       [ 41.        , 101.22014822,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 65.        ,  98.87774465,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   1.        ,   0.        ],\n",
       "       [ 48.        ,  97.95986808,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 50.        , 100.96630736,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ],\n",
       "       [ 52.        , 104.89677622,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ],\n",
       "       [ 55.        , 102.05727966,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer.fit_transform(X_train)\n",
    "# transformer.fit_transform(X_train).shape\n",
    "\n",
    "transformer.fit_transform(X_test)\n",
    "# transformer.fit_transform(X_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Buyer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Buyer\n",
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "5      1\n",
       "6      0\n",
       "7      0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = [\"Yes\",\"No\",\"Yes\",\"Yes\",\"No\",\"Yes\",\"No\",\"No\"]\n",
    "dt = pd.DataFrame(Data,columns=[\"Buyer\"])\n",
    "Encoder = LabelEncoder()\n",
    "L_encoder = Encoder.fit_transform(dt[\"Buyer\"])\n",
    "# print(L_encoder)\n",
    "dt[\"Buyer\"] = L_encoder\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OrdinalEncoding\n",
    "Data = [[\"High\"],[\"High\"],[\"Medium\"],[\"Low\"],[\"Low\"],[\"Low\"],[\"Low\"],[\"Medium\"],[\"High\"]]\n",
    "dt = pd.DataFrame(Data,columns=[\"Fever\"])\n",
    "# dt_columns = dt[['Fever']]\n",
    "Encoder = OrdinalEncoder(categories=[[\"Low\",\"Medium\",\"High\"]])\n",
    "O_encoder = Encoder.fit_transform(dt)\n",
    "O_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>class_First</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   age  sibsp  parch     fare    who  adult_male deck  \\\n",
       "0           0       3  22.0      1      0   7.2500    man        True  NaN   \n",
       "1           1       1  38.0      1      0  71.2833  woman       False    C   \n",
       "2           1       3  26.0      0      0   7.9250  woman       False  NaN   \n",
       "3           1       1  35.0      1      0  53.1000  woman       False    C   \n",
       "4           0       3  35.0      0      0   8.0500    man        True  NaN   \n",
       "..        ...     ...   ...    ...    ...      ...    ...         ...  ...   \n",
       "886         0       2  27.0      0      0  13.0000    man        True  NaN   \n",
       "887         1       1  19.0      0      0  30.0000  woman       False    B   \n",
       "888         0       3   NaN      1      2  23.4500  woman       False  NaN   \n",
       "889         1       1  26.0      0      0  30.0000    man        True    C   \n",
       "890         0       3  32.0      0      0   7.7500    man        True  NaN   \n",
       "\n",
       "     embark_town alive  alone  sex_female  sex_male  embarked_C  embarked_Q  \\\n",
       "0    Southampton    no  False       False      True       False       False   \n",
       "1      Cherbourg   yes  False        True     False        True       False   \n",
       "2    Southampton   yes   True        True     False       False       False   \n",
       "3    Southampton   yes  False        True     False       False       False   \n",
       "4    Southampton    no   True       False      True       False       False   \n",
       "..           ...   ...    ...         ...       ...         ...         ...   \n",
       "886  Southampton    no   True       False      True       False       False   \n",
       "887  Southampton   yes   True        True     False       False       False   \n",
       "888  Southampton    no  False        True     False       False       False   \n",
       "889    Cherbourg   yes   True       False      True        True       False   \n",
       "890   Queenstown    no   True       False      True       False        True   \n",
       "\n",
       "     embarked_S  class_First  class_Second  class_Third  \n",
       "0          True        False         False         True  \n",
       "1         False         True         False        False  \n",
       "2          True        False         False         True  \n",
       "3          True         True         False        False  \n",
       "4          True        False         False         True  \n",
       "..          ...          ...           ...          ...  \n",
       "886        True        False          True        False  \n",
       "887        True         True         False        False  \n",
       "888        True        False         False         True  \n",
       "889       False         True         False        False  \n",
       "890       False        False         False         True  \n",
       "\n",
       "[891 rows x 20 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHotEncoding\n",
    "dt = sns.load_dataset(\"titanic\")\n",
    "# dt.sample(5)\n",
    "\n",
    "dt_columns = [\"sex\",\"embarked\",\"class\"]\n",
    "pd_ohe_encoder = pd.get_dummies(dt, columns=dt_columns)\n",
    "pd_ohe_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 2673 stored elements and shape (891, 9)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 6)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (2, 8)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (3, 6)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (4, 8)\t1.0\n",
      "  (5, 1)\t1.0\n",
      "  (5, 3)\t1.0\n",
      "  (5, 8)\t1.0\n",
      "  (6, 1)\t1.0\n",
      "  (6, 4)\t1.0\n",
      "  (6, 6)\t1.0\n",
      "  (7, 1)\t1.0\n",
      "  (7, 4)\t1.0\n",
      "  (7, 8)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  :\t:\n",
      "  (882, 8)\t1.0\n",
      "  (883, 1)\t1.0\n",
      "  (883, 4)\t1.0\n",
      "  (883, 7)\t1.0\n",
      "  (884, 1)\t1.0\n",
      "  (884, 4)\t1.0\n",
      "  (884, 8)\t1.0\n",
      "  (885, 0)\t1.0\n",
      "  (885, 3)\t1.0\n",
      "  (885, 8)\t1.0\n",
      "  (886, 1)\t1.0\n",
      "  (886, 4)\t1.0\n",
      "  (886, 7)\t1.0\n",
      "  (887, 0)\t1.0\n",
      "  (887, 4)\t1.0\n",
      "  (887, 6)\t1.0\n",
      "  (888, 0)\t1.0\n",
      "  (888, 4)\t1.0\n",
      "  (888, 8)\t1.0\n",
      "  (889, 1)\t1.0\n",
      "  (889, 2)\t1.0\n",
      "  (889, 6)\t1.0\n",
      "  (890, 1)\t1.0\n",
      "  (890, 3)\t1.0\n",
      "  (890, 8)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# dt_columns = [[\"sex\",\"embarked\",\"class\"]]\n",
    "# Encoder = OneHotEncoder()\n",
    "# ohe_encoder = Encoder.fit_transform(dt_columns)\n",
    "# print(ohe_encoder)\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "cat_col = df[['sex', 'embarked', 'class']]\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(cat_col)\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdullah khan\\AppData\\Local\\Temp\\ipykernel_12188\\1953283369.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dt[\"age\"].fillna(dt[\"age\"].mean(),inplace=True)\n",
      "C:\\Users\\Abdullah khan\\AppData\\Local\\Temp\\ipykernel_12188\\1953283369.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dt[\"fever\"].fillna(dt[\"fever\"].mean(),inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column Transformer\n",
    "dt = pd.read_csv(\"D:\\\\Machine learning\\\\DataSets\\\\covid_data_with_missing_values.csv\")\n",
    "# dt.sample(5)\n",
    "\n",
    "# let's fill missing values \n",
    "# Condsider this as dummy it will not effect the orignal outcome if we replace it with mean values\n",
    "dt[dt[\"age\"].isnull()]\n",
    "\n",
    "dt[\"age\"].fillna(dt[\"age\"].mean(),inplace=True)\n",
    "dt[dt[\"age\"].isnull()]\n",
    "\n",
    "dt[\"fever\"].fillna(dt[\"fever\"].mean(),inplace=True)\n",
    "dt[dt[\"fever\"].isnull()]\n",
    "\n",
    "\n",
    "dt[\"age\"] = dt[\"age\"].astype(\"int\")\n",
    "dt[\"fever\"] = dt[\"fever\"].astype(\"int\")\n",
    "\n",
    "# dt[\"age\"].dtype\n",
    "dt[\"age\"].isnull().sum()\n",
    "# dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>fever</th>\n",
       "      <th>cough</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>52</td>\n",
       "      <td>Female</td>\n",
       "      <td>102</td>\n",
       "      <td>High</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>104</td>\n",
       "      <td>Low</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>98</td>\n",
       "      <td>High</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>103</td>\n",
       "      <td>High</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>103</td>\n",
       "      <td>Low</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  fever cough      city\n",
       "187   52  Female    102  High   Chicago\n",
       "134   33    Male    104   Low   Phoenix\n",
       "383   58    Male     98  High  New York\n",
       "244   67    Male    103  High   Chicago\n",
       "482   37    Male    103   Low   Houston"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dt.drop(columns=[\"has_covid\"]), dt[\"has_covid\"], test_size=0.2, random_state=42)\n",
    "X_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column Transformers\n",
    "data = sns.load_dataset(\"tips\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=[\"total_bill\"]), data[\"total_bill\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_bill    0\n",
       "tip           0\n",
       "sex           0\n",
       "smoker        0\n",
       "day           0\n",
       "time          0\n",
       "size          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() # We use simple imputer to fill the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = SimpleImputer(strategy=\"mean\")\n",
    "# si.fit(X_train[[\"size\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 77 stored elements and shape (49, 4)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(drop=\"first\")\n",
    "X_train_gender_day = ohe.fit_transform(X_train[[\"sex\",\"day\"]])\n",
    "X_test_gender_day = ohe.fit_transform(X_test[[\"sex\",\"day\"]])\n",
    "X_train_gender_day\n",
    "X_test_gender_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now with column transforemers\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# transformer = ColumnTransformer(transformers=[\n",
    "    \n",
    "# ]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = {\n",
    "    'age': [25, 30, None, 40],\n",
    "    'income': [50000, 60000, 70000, None],\n",
    "    'gender': ['M', 'F', 'M', 'F'],\n",
    "    'city': ['NY', 'LA', 'NY', 'SF'],\n",
    "    'review': ['Great product!', 'Not bad', 'Amazing', 'Could be better'],\n",
    "    'target': [1, 0, 1, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>gender</th>\n",
       "      <th>city</th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NY</td>\n",
       "      <td>Great product!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>F</td>\n",
       "      <td>LA</td>\n",
       "      <td>Not bad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NY</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>SF</td>\n",
       "      <td>Could be better</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age   income gender city           review  target\n",
       "0  25.0  50000.0      M   NY   Great product!       1\n",
       "1  30.0  60000.0      F   LA          Not bad       0\n",
       "2   NaN  70000.0      M   NY          Amazing       1\n",
       "3  40.0      NaN      F   SF  Could be better       0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Define transformers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"Scalar\", StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "text_transformer = Pipeline(steps=[\n",
    "    (\"tfidf\", TfidfVectorizer())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, ['age', 'income']),\n",
    "        ('cat', categorical_transformer, ['gender', 'city']),\n",
    "        ('text', text_transformer, 'review')\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Create pipelines\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "preprocessor\n",
    "model_pipeline\n",
    "\n",
    "# Fit and Predict\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
